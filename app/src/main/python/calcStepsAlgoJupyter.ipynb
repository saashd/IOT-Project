{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.signal import find_peaks,detrend\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "import glob\n",
    "from scipy.signal import kaiserord, lfilter, firwin\n",
    "import os\n",
    "import shutil\n",
    "from random import shuffle\n",
    "from math import floor\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_name):\n",
    "    actual_steps=pd.read_csv(file_name,skiprows=2,nrows=1).values[0][1]\n",
    "    new_df = pd.read_csv(file_name,skiprows=5)\n",
    "    x_arr=np.array(new_df[\"ACC X\"])\n",
    "    y_arr=np.array(new_df[\"ACC Y\"])\n",
    "    z_arr=np.array(new_df[\"ACC Z\"])\n",
    "    mag_arr = np.sqrt(x_arr**2 + y_arr**2 + z_arr**2)              \n",
    "    mean_mag_arr=mag_arr-np.mean(mag_arr)\n",
    "    new_df['Mean Magnitude']=mean_mag_arr\n",
    "    new_df['Time']=new_df[\"Time [sec]\"]-new_df[\"Time [sec]\"].iloc[[0]].values[0] \n",
    "    t_arr=np.array(new_df[\"Time\"]) \n",
    "    \n",
    "    sample_rate = None\n",
    "    for i in range(len(t_arr)):\n",
    "        if t_arr[i]-t_arr[0]>1.0:\n",
    "            sample_rate=i\n",
    "            break\n",
    "    duration=new_df['Time'].iloc[[-1]].values[0]\n",
    "    data.append([file_name,duration,sample_rate,actual_steps])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list_from_dir(datadir):\n",
    "    all_files=glob.glob(datadir+\"/*.csv\") \n",
    "    return all_files\n",
    "\n",
    "def randomize_files(file_list):\n",
    "    shuffle(file_list)\n",
    "    \n",
    "def get_training_and_testing_sets(file_list):\n",
    "    split = 0.7\n",
    "    split_index = floor(len(file_list) * split)\n",
    "    training = file_list[:split_index]\n",
    "    testing = file_list[split_index:]\n",
    "    return training, testing\n",
    "\n",
    "def fourier_extrapolation(x, n_harm):\n",
    "    n = x.size\n",
    "    t = np.arange(0, n)\n",
    "    p = np.polyfit(t, x, 1)  # find linear trend in x\n",
    "    x_notrend = x - p[0] * t  # detrended x\n",
    "    x_freqdom = np.fft.fft(x_notrend)  # detrended x in frequency domain\n",
    "    f = np.fft.fftfreq(n)  # frequencies\n",
    "    indexes = list(range(n))\n",
    "    # sort indexes by frequency, lower -> higher\n",
    "    indexes.sort(key=lambda i: np.absolute(f[i]))\n",
    "\n",
    "    t = np.arange(0, n)\n",
    "    restored_sig = np.zeros(t.size)\n",
    "    for i in indexes[:1 + n_harm * 2]:\n",
    "        ampli = np.absolute(x_freqdom[i]) / n  # amplitude\n",
    "        phase = np.angle(x_freqdom[i])  # phase\n",
    "        restored_sig += ampli * np.cos(2 * np.pi * f[i] * t + phase)\n",
    "    return restored_sig + p[0] * t\n",
    "\n",
    "def get_mag_mean_filter_kernel5(file_name,mode,k_val=None,isPrint=False):\n",
    "    actual_steps=pd.read_csv(file_name,skiprows=2,nrows=1).values[0][1]\n",
    "    new_df = pd.read_csv(file_name,skiprows=5)\n",
    "    x_arr=np.array(new_df[\"ACC X\"])\n",
    "    y_arr=np.array(new_df[\"ACC Y\"])\n",
    "    z_arr=np.array(new_df[\"ACC Z\"])\n",
    "    mag_arr = np.sqrt(x_arr**2 + y_arr**2 + z_arr**2)              \n",
    "    mean_mag_arr=mag_arr-np.mean(mag_arr)\n",
    "    new_df['Mean Magnitude']=mean_mag_arr\n",
    "    new_df['Time']=new_df[\"Time [sec]\"]-new_df[\"Time [sec]\"].iloc[[0]].values[0] \n",
    "    t_arr=np.array(new_df[\"Time\"])   \n",
    "   \n",
    "    \n",
    "    # Convolution\n",
    "    filter_window_size=7\n",
    "    if mode == \"running\":\n",
    "        filter_window_size=5\n",
    "    mag_mean_filter_kernel5 = np.convolve(mean_mag_arr, \n",
    "                           np.ones((filter_window_size,))/filter_window_size, \n",
    "                           mode='valid')\n",
    "\n",
    "\n",
    "    \n",
    "    sample_rate = None\n",
    "    for i in range(len(t_arr)):\n",
    "        if t_arr[i]-t_arr[0]>1.0:\n",
    "            sample_rate=i\n",
    "            break    \n",
    "    signal=mag_mean_filter_kernel5\n",
    "    if sample_rate<10.0:\n",
    "        sample_rate=10.0\n",
    "\n",
    "    nsamples = len(mag_mean_filter_kernel5)\n",
    "    t = np.arange(nsamples) / sample_rate\n",
    "\n",
    "    # The Nyquist rate of the signal acc to Nyquist Theorem.\n",
    "    nyq_rate = sample_rate / 2.0\n",
    "    width = 5.0/nyq_rate\n",
    "    if mode==\"walking\":\n",
    "        ripple_db = 50.0\n",
    "        N, beta = kaiserord(ripple_db, width)\n",
    "        if sample_rate<15.0:\n",
    "            cutoff_hz=4.5\n",
    "        else:\n",
    "            cutoff_hz=3.0\n",
    "# FIR filter        \n",
    "    if mode==\"running\":\n",
    "        ripple_db = 50.0\n",
    "        N, beta = kaiserord(ripple_db, width)\n",
    "        if sample_rate<15.0:\n",
    "            cutoff_hz=4.5\n",
    "        else:\n",
    "            cutoff_hz=4.0\n",
    "    taps = firwin(N, cutoff_hz/nyq_rate, window=('kaiser', beta))\n",
    "\n",
    "    signal = lfilter(taps, 1.0, mag_mean_filter_kernel5)\n",
    "        \n",
    "    ax=None\n",
    "    \n",
    "    if isPrint:\n",
    "            #  Plotting\n",
    "        fig = plt.figure(figsize=(25,5))\n",
    "        ax = fig.subplots()\n",
    "        ax.plot(mean_mag_arr,label = 'Mean Magnutude Signal',linestyle='-.',color='gray',alpha=0.4)\n",
    "        ax.plot(mag_mean_filter_kernel5,label = 'Signal after Convo',linestyle='--',color='orange')\n",
    "\n",
    "        ax.plot(signal,label = 'Signal after FIR Filter',color='green')\n",
    "    \n",
    "    return signal,actual_steps,sample_rate,k_val,ax\n",
    "\n",
    "def get_all_maxima(data):\n",
    "    # Returns all posible maxima of the signal\n",
    "    peaks=[]\n",
    "    n=len(data)-1\n",
    "    i=1\n",
    "    while i< n:\n",
    "        if data[i - 1] < data[i]:\n",
    "            i_ahead = i + 1\n",
    "            while i_ahead < n and data[i_ahead] == data[i]:\n",
    "                i_ahead += 1\n",
    "            if data[i_ahead] < data[i]:\n",
    "                peaks.append( (i + i_ahead - 1) // 2)\n",
    "                i = i_ahead\n",
    "        i += 1\n",
    "\n",
    "    return np.array(peaks,dtype=np.intp)\n",
    "\n",
    "def get_peaks_by_threshold(data, maxima_pos, threshold):\n",
    "    # Returns maxima of the signal filtered by threshold\n",
    "    data=np.array(data)\n",
    "    maxima_pos=np.array(maxima_pos)\n",
    "    count=0\n",
    "    peaks=[]\n",
    "    peaks_pos=[]\n",
    "    for i in range(1,len(data)-1):\n",
    "        if i in maxima_pos:\n",
    "            left=data[i-1]\n",
    "            right=data[i+1]\n",
    "            peak=data[i]\n",
    "            min_val=min(peak-right,peak-left)\n",
    "            if min_val>=threshold:\n",
    "                peaks.append(peak)\n",
    "                peaks_pos.append(i)\n",
    "                count+=1\n",
    "    return np.array(peaks_pos),np.array(peaks)\n",
    "\n",
    "def calc_threshold(data,actual_steps):\n",
    "    min_diff=None\n",
    "    best_thresh=None\n",
    "    calc_peaks=None\n",
    "    for threshold in np.arange(0,0.1,0.001):\n",
    "        maxima_pos = get_all_maxima(data)\n",
    "        peaks_pos,peaks = get_peaks_by_threshold(data, maxima_pos, threshold)\n",
    "        diff=abs(actual_steps-len(peaks))\n",
    "        if min_diff is None or min_diff>diff:\n",
    "            min_diff=diff\n",
    "            best_thresh=threshold\n",
    "            calc_peaks=len(peaks)\n",
    "    return best_thresh\n",
    "\n",
    "\n",
    "def set_threshold_dict(sample_rate,threshold_dict,data,actual_steps):\n",
    "    if sample_rate is None or sample_rate<=5:\n",
    "        threshold_dict[5].append(calc_threshold(data,actual_steps))\n",
    "    elif sample_rate<=10:\n",
    "        threshold_dict[10].append(calc_threshold(data,actual_steps))\n",
    "    elif sample_rate<=20:\n",
    "        threshold_dict[20].append(calc_threshold(data,actual_steps))\n",
    "    elif sample_rate<=30:\n",
    "        threshold_dict[30].append(calc_threshold(data,actual_steps))\n",
    "    elif sample_rate<=40:\n",
    "        threshold_dict[40].append(calc_threshold(data,actual_steps))\n",
    "    elif sample_rate<=50:\n",
    "        threshold_dict[50].append(calc_threshold(data,actual_steps))\n",
    "    elif sample_rate<=60:\n",
    "        threshold_dict[60].append(calc_threshold(data,actual_steps))\n",
    "    elif sample_rate<=70:\n",
    "        threshold_dict[70].append(calc_threshold(data,actual_steps))\n",
    "    elif sample_rate<=80:\n",
    "        threshold_dict[80].append(calc_threshold(data,actual_steps))\n",
    "    elif sample_rate<=90:\n",
    "        threshold_dict[90].append(calc_threshold(data,actual_steps))\n",
    "    else:\n",
    "        threshold_dict[100].append(calc_threshold(data,actual_steps))\n",
    "        \n",
    "def get_thershold(threshold_dict,sample_rate):\n",
    "    if sample_rate is None or sample_rate<=5:\n",
    "        return threshold_dict[5]\n",
    "    elif sample_rate<=10:\n",
    "        return threshold_dict[10]\n",
    "    elif sample_rate<=20:\n",
    "        return threshold_dict[20]\n",
    "    elif sample_rate<=30:\n",
    "        return threshold_dict[30]\n",
    "    elif sample_rate<=40:\n",
    "        return threshold_dict[40]\n",
    "    elif sample_rate<=50:\n",
    "        return threshold_dict[50]\n",
    "    elif sample_rate<=60:\n",
    "        return threshold_dict[60]\n",
    "    elif sample_rate<=70:\n",
    "        return threshold_dict[70]\n",
    "    elif sample_rate<=80:\n",
    "        return threshold_dict[80]\n",
    "    elif sample_rate<=90:\n",
    "        return threshold_dict[90]\n",
    "    else:\n",
    "        return threshold_dict[100]\n",
    "\n",
    "\n",
    "        \n",
    "def check_algo(mode, getSignal,train,test):    \n",
    "    threshold_dict={5:[],10:[],15:[],20:[],25:[],30:[],35:[],40:[],50:[],60:[],70:[],80:[],90:[],100:[]}\n",
    "    for file in train:\n",
    "        data,actual_steps,sample_rate,k_val,_=getSignal(file,mode,None,False)\n",
    "        plt.close('all')\n",
    "        set_threshold_dict(sample_rate,threshold_dict,data,actual_steps)\n",
    "    optimal_threshold_dict={}\n",
    "    for key,val in threshold_dict.items():\n",
    "        if len(threshold_dict[key])!=0:\n",
    "            optimal_thresh=np.array(threshold_dict[key]).mean()\n",
    "            optimal_threshold_dict[key]=optimal_thresh\n",
    "        else:\n",
    "            optimal_threshold_dict[key]=0\n",
    "        \n",
    "    print(optimal_threshold_dict)\n",
    "    \n",
    "    tot_diff=0\n",
    "    all_real_steps=0\n",
    "    all_calc_steps=0\n",
    "    \n",
    "    for file in test:\n",
    "        data,actual_steps,sample_rate,k_val,ax=getSignal(file,mode,k_val,True)\n",
    "        maxima_pos = get_all_maxima(data)\n",
    "        threshold=get_thershold(optimal_threshold_dict,sample_rate)\n",
    "        peaks_pos,peaks = get_peaks_by_threshold(data, maxima_pos, threshold)\n",
    "        diff=abs(actual_steps-len(peaks))\n",
    "        #adding text inside the plot\n",
    "        anchored_text = AnchoredText(file+\" sample rate is: \"+str(sample_rate)+\n",
    "                                    \"\\n COUNT OF ACTUAL STEPS: \"+str(actual_steps)+\n",
    "                                     \"\\n COUNT OF CALCULATED STEPS: \"+str(len(peaks))+\n",
    "                                     \"\\n Difference: \"+str(diff), loc=2)\n",
    "        ax.add_artist(anchored_text)\n",
    "\n",
    "        \n",
    "        ax.scatter(peaks_pos,peaks, color = 'r', s = 15, marker = 'D', label = 'Maxima')\n",
    "        ax.legend(loc=1)\n",
    "        ax.grid()\n",
    "        plt.savefig(file+\".png\")\n",
    "        plt.show()\n",
    "        all_real_steps+=actual_steps\n",
    "        all_calc_steps+=len(peaks)\n",
    "        tot_diff+=diff\n",
    "        print(\"-\"*50)\n",
    " \n",
    "    print(\"Avarage Difference: \",(tot_diff/len(test)))\n",
    "    print(\"Difference in %\",(tot_diff*100/all_real_steps))\n",
    "    print(\"All Actual Steps: \",all_real_steps)\n",
    "    print(\"Tot Difference: \",tot_diff)\n",
    "    \n",
    "    print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Walking Steps: Data Analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=get_file_list_from_dir(\"data/walk_all\")\n",
    "files.sort()\n",
    "data=[]\n",
    "for file in files:\n",
    "    get_data(file)\n",
    "    \n",
    "df=pd.DataFrame(data,columns=[\"Name\",\"Duration\",\"SR\",\"Steps\"])\n",
    "df['Name'] = df['Name'].str.replace(\"data/walk_all\",\"\")\n",
    "df['Name'] = df['Name'].str.replace(\"\\\\\",\"\")\n",
    "# df['Name'] = df['Name'].str.replace(\".csv\",\"\")\n",
    "df.sort_values(by=['Duration',\"Steps\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "df.boxplot(column=['Steps'],showmeans=True)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "col = np.where(df['Duration']<50,'r',np.where(df[\"Steps\"]<95,'b','k'))\n",
    "# Scatter plot\n",
    "ax = df.plot.scatter(x='Duration', y='Steps', alpha=0.7,s=50,c=col)\n",
    "\n",
    "# Annotate each data point\n",
    "for i, txt in enumerate(df[\"Name\"]):\n",
    "    ax.annotate(txt, (df['Duration'].iat[i]+0.05, df[\"Steps\"].iat[i]),xytext=(10,-5),textcoords='offset points',\n",
    "                family='sans-serif', fontsize=20, color='darkslategrey')\n",
    "plt.xticks(np.arange(20, 100, 5))\n",
    "plt.yticks(np.arange(65, 140, 5))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 50   \n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.hist(df[\"SR\"], num_bins, color ='green',alpha = 0.5)\n",
    "\n",
    "plt.title('Historgtam of Data Records by Sample Rate ',\n",
    "          fontweight =\"bold\")\n",
    "\n",
    "plt.xticks(np.arange(0, 40, 2))\n",
    "plt.yticks(np.arange(0, 12, 2))\n",
    "    \n",
    "plt.xlabel('Sample Rate in hz')  \n",
    "plt.ylabel('Number of Data Records')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 50  \n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.hist(df[\"Duration\"], num_bins, color ='blue',alpha = 0.5)\n",
    "\n",
    "plt.title('Historgtam of Data Records by Duration ',\n",
    "          fontweight =\"bold\")\n",
    "\n",
    "plt.xticks(np.arange(20, 105, 5))\n",
    "plt.yticks(np.arange(0, 30, 2))\n",
    "    \n",
    "plt.xlabel('Duration in sec')  \n",
    "plt.ylabel('Number of Data Records')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 50  \n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.hist(df[\"Steps\"], num_bins, color ='gold',alpha = 0.5)\n",
    "\n",
    "plt.title('Historgtam of Data Records by Steps Counted ',\n",
    "          fontweight =\"bold\")\n",
    "\n",
    "plt.xticks(np.arange(60, 150, 10))\n",
    "plt.yticks(np.arange(0, 10, 2))\n",
    "    \n",
    "plt.xlabel('Number of Steps Counted')  \n",
    "plt.ylabel('Number of Data Records')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data with low Sample Rate\n",
    "low_sr_df=df.sort_values(by=['SR'])\n",
    "low_sr_df=low_sr_df[low_sr_df['SR'] <=5]\n",
    "low_sr_list=list(low_sr_df[\"Name\"])\n",
    "low_sr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA THAT WAS RECORDED FOR LESS THEN A MINUTE\n",
    "low_dur_df = df[df['Duration'] <=50]\n",
    "low_dur_list=list(low_dur_df[\"Name\"])\n",
    "low_dur_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data with low Sample Rate of Duration less then a minute to another directory.\n",
    "unused=low_dur_list+low_sr_list\n",
    "destination = \"data/walk_all/unused\"\n",
    "if not os.path.exists(destination):\n",
    "    os.makedirs(destination)\n",
    "for file_name in unused:\n",
    "    try:\n",
    "        shutil.move(os.path.join(\"data/walk_all\", file_name), destination)\n",
    "    except:\n",
    "        pass\n",
    "pprint(unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=get_file_list_from_dir(\"data/walk_all\")\n",
    "files.sort()\n",
    "data=[]\n",
    "for file in files:\n",
    "    get_data(file)\n",
    "    \n",
    "df=pd.DataFrame(data,columns=[\"Name\",\"Duration\",\"SR\",\"Steps\"])\n",
    "df['Name'] = df['Name'].str.replace(\"data/walk_all\",\"\")\n",
    "df['Name'] = df['Name'].str.replace(\"\\\\\",\"\")\n",
    "df['Name'] = df['Name'].str.replace(\".csv\",\"\")\n",
    "df.sort_values(by=['Duration',\"Steps\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Walking Steps: Steps Counting Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=get_file_list_from_dir(\"data/walk_all\")\n",
    "randomize_files(files)\n",
    "train,test=get_training_and_testing_sets(files)\n",
    "train.sort()\n",
    "test.sort()\n",
    "print(len(test),len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check_algo(\"walking\",get_mag_mean_filter_kernel5,train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Running Steps: Data Analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=get_file_list_from_dir(\"data/run_all\")\n",
    "files.sort()\n",
    "data=[]\n",
    "for file in files:\n",
    "    get_data(file)\n",
    "    \n",
    "df=pd.DataFrame(data,columns=[\"Name\",\"Duration\",\"SR\",\"Steps\"])\n",
    "df['Name'] = df['Name'].str.replace(\"data/run_all\",\"\")\n",
    "df['Name'] = df['Name'].str.replace(\"\\\\\",\"\")\n",
    "# df['Name'] = df['Name'].str.replace(\".csv\",\"\")\n",
    "df.sort_values(by=['Duration',\"Steps\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "df.boxplot(column=['Steps'],showmeans=True)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "col = np.where(df['Duration']<50,'r',np.where(df[\"Steps\"]<139,'b','k'))\n",
    "# Scatter plot\n",
    "ax = df.plot.scatter(x='Duration', y='Steps', alpha=0.7,s=50,c=col)\n",
    "\n",
    "# Annotate each data point\n",
    "for i, txt in enumerate(df[\"Name\"]):\n",
    "#         ax.annotate(k, v,\n",
    "#                 xytext=(10,-5), textcoords='offset points',\n",
    "#                 family='sans-serif', fontsize=18, color='darkslategrey')\n",
    "    ax.annotate(txt, (df['Duration'].iat[i]+0.05, df[\"Steps\"].iat[i]),xytext=(10,-5),textcoords='offset points',\n",
    "                family='sans-serif', fontsize=20, color='darkslategrey')\n",
    "plt.xticks(np.arange(0, 150, 5))\n",
    "plt.yticks(np.arange(65, 200, 5))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 50   \n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.hist(df[\"SR\"], num_bins, color ='green',alpha = 0.5)\n",
    "\n",
    "plt.title('Historgtam of Data Records by Sample Rate ',\n",
    "          fontweight =\"bold\")\n",
    "\n",
    "plt.xticks(np.arange(0, 40, 2))\n",
    "plt.yticks(np.arange(0, 12, 2))\n",
    "    \n",
    "plt.xlabel('Sample Rate in hz')  \n",
    "plt.ylabel('Number of Data Records')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 50  \n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.hist(df[\"Duration\"], num_bins, color ='blue',alpha = 0.5)\n",
    "\n",
    "plt.title('Historgtam of Data Records by Duration ',\n",
    "          fontweight =\"bold\")\n",
    "\n",
    "plt.xticks(np.arange(20, 160, 5))\n",
    "plt.yticks(np.arange(0, 30, 2))\n",
    "    \n",
    "plt.xlabel('Duration in sec')  \n",
    "plt.ylabel('Number of Data Records')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 50  \n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.hist(df[\"Steps\"], num_bins, color ='gold',alpha = 0.5)\n",
    "\n",
    "plt.title('Historgtam of Data Records by Steps Counted ',\n",
    "          fontweight =\"bold\")\n",
    "\n",
    "plt.xticks(np.arange(60, 200, 10))\n",
    "plt.yticks(np.arange(0, 10, 2))\n",
    "    \n",
    "plt.xlabel('Number of Steps Counted')  \n",
    "plt.ylabel('Number of Data Records')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data with low Sample Rate\n",
    "low_sr_df=df.sort_values(by=['SR'])\n",
    "low_sr_df=low_sr_df[low_sr_df['SR'] <=5]\n",
    "low_sr_list=list(low_sr_df[\"Name\"])\n",
    "low_sr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA THAT WAS RECORDED FOR LESS THEN A MINUTE\n",
    "low_dur_df = df[df['Duration'] <=50]\n",
    "low_dur_list=list(low_dur_df[\"Name\"])\n",
    "low_dur_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data with low Sample Rate of Duration less then a minute to another directory.\n",
    "unused=low_dur_list+low_sr_list\n",
    "destination = \"data/run_all/unused\"\n",
    "if not os.path.exists(destination):\n",
    "    os.makedirs(destination)\n",
    "for file_name in unused:\n",
    "    try:\n",
    "        shutil.move(os.path.join(\"data/run_all\", file_name), destination)\n",
    "    except:\n",
    "        pass\n",
    "pprint(unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=get_file_list_from_dir(\"data/run_all\")\n",
    "files.sort()\n",
    "data=[]\n",
    "for file in files:\n",
    "    get_data(file)\n",
    "    \n",
    "df=pd.DataFrame(data,columns=[\"Name\",\"Duration\",\"SR\",\"Steps\"])\n",
    "df['Name'] = df['Name'].str.replace(\"data/run_all\",\"\")\n",
    "df['Name'] = df['Name'].str.replace(\"\\\\\",\"\")\n",
    "df['Name'] = df['Name'].str.replace(\".csv\",\"\")\n",
    "df.sort_values(by=['Duration',\"Steps\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Running Steps: Steps Counting Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=get_file_list_from_dir(\"data/run_all\")\n",
    "randomize_files(files)\n",
    "train,test=get_training_and_testing_sets(files)\n",
    "train.sort()\n",
    "test.sort()\n",
    "print(len(test),len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_algo(\"running\",get_mag_mean_filter_kernel5,train,test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
